{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3b.1**\n",
    "\n",
    "Перед вами опять до боли знакомый набор данных детектора черенковского излучения. Ваша задача переписать классификатор из блокнота `torch.ipynb` с использованием фреймворка TensorFlow и API Keras. Почти весь код уже написан, вам осталось самостоятельно заполнить пропущенные места, используя документацию (https://www.tensorflow.org/api_docs/python/tf/keras/layers):\n",
    "\n",
    "* Аналогом `torch.nn.Sequential` является `tf.keras.Sequential`,\n",
    "* Полносвязный слой удобно задавать используя `tf.keras.layers.Dense`.\n",
    "\n",
    "Используйте значения метапараметров (количество скрытых нейронов, скорость обучения и т.п.) определенные при работе с аналогичным заданием из блокнота `torch.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "names = [\"length\", \"width\", \"size\", \"conc\", \"conc1\", \"asym\", \"m3long\", \"m3trans\", \"alpha\", \"dist\", \"class\"]\n",
    "data = pd.read_csv('magic04.csv', names=names)\n",
    "\n",
    "x = np.asarray(data.iloc[:, :-1]).astype(np.float32)\n",
    "y = np.asarray(data.iloc[:, [-1]])\n",
    "y = (y == 'g').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(5)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(43)\n",
    "\n",
    "INPUT_DIM  = x.shape[1]\n",
    "HIDDEN_DIM = # ???\n",
    "OUTPUT_DIM = y.shape[1]\n",
    "\n",
    "model = # модель потерялась\n",
    "\n",
    "learning_rate = 1e-3\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='MSE', metrics=['accuracy'])\n",
    "\n",
    "_ = model.fit(train_dataset, epochs=50, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "y_true = y_test\n",
    "scores = model.predict(x_test)\n",
    "\n",
    "min_score, max_score = np.min(scores), np.max(scores)\n",
    "bins = np.linspace(min_score, max_score, 25)\n",
    "plt.figure()\n",
    "plt.hist(scores[y_true.reshape(-1) == 0], bins, alpha=0.5, label='Hadron (negative)')\n",
    "plt.hist(scores[y_true.reshape(-1) == 1], bins, alpha=0.5, label='Gamma (positive)')\n",
    "plt.xlabel(\"Decision function (value)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_true, scores)\n",
    "auc = sklearn.metrics.roc_auc_score(y_true, scores)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "print(\"AUC                       = {:.4f}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3b.2**\n",
    "\n",
    "В блокноте `torch.ipynb` реализован автоэнкодер для набора рукописных цифр MNIST на базе свёрточных нейронных сетей. Настало время переписать и его с использованием фреймворка TensorFlow и API Keras.\n",
    "Используйте документацию (https://www.tensorflow.org/api_docs/python/tf/keras/layers), чтобы воспроизвести известную вам существующую архитектуру с помощью нового фреймворка.\n",
    "\n",
    "* Нарисуйте четыре случайных изображения из тестового набора данных: исходное изображение, закодированное сжатое представление в виде гистограмы, и раскодированное изображение.\n",
    "* Попробуйте сгенерировать четыре случайных изображения, подав на вход декодера случайные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(43)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, x_train)).shuffle(1000).batch(4)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, x_test)).shuffle(1000).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (28, 28)\n",
    "HIDDEN1_CH = 24\n",
    "HIDDEN2_CH = 36\n",
    "LATENT_DIM = 8\n",
    "\n",
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=INPUT_SHAPE, name='encoder_input')\n",
    "    \n",
    "    encoder = tf.keras.Sequential([\n",
    "        inputs,\n",
    "        # слои потерялись\n",
    "    ])\n",
    "    \n",
    "    decoder = tf.keras.Sequential([\n",
    "        # и здесь тоже слои потерялись\n",
    "    ])\n",
    "\n",
    "    autoencoder = tf.keras.Model(inputs=inputs, outputs=decoder(encoder(inputs)))\n",
    "    \n",
    "    return autoencoder, encoder, decoder\n",
    "\n",
    "model, encoder, decoder = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(41)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='MSE')\n",
    "\n",
    "_ = model.fit(train_dataset, epochs=6, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7.5))\n",
    "n_col = 4\n",
    "for i in range(n_col):\n",
    "    ax = plt.subplot(3, n_col, i + 1)\n",
    "    inp = #\n",
    "    plt.imshow(inp, cmap='gray')\n",
    "    ax = plt.subplot(3, n_col, i + 1 + n_col)\n",
    "    encoded = #\n",
    "    plt.bar(np.arange(encoded.shape[0]), encoded)\n",
    "    ax = plt.subplot(3, n_col, i + 1 + n_col * 2)\n",
    "    decoded = #\n",
    "    plt.imshow(decoded, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)\n",
    "\n",
    "encoded = #\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "n_col = 4\n",
    "for i in range(n_col):\n",
    "    ax = plt.subplot(2, n_col, i + 1)\n",
    "    plt.bar(np.arange(encoded.shape[1]), encoded[i,:])\n",
    "    ax = plt.subplot(2, n_col, i + 1 + n_col)\n",
    "    decoded = #\n",
    "    plt.imshow(decoded, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
